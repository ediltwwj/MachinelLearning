梯度下降法（GradientDescent)
不是一个机器学习算法，
是一种基于搜索的最优化方法
作用：最小化一个损失函数
梯度上升法：最大化一个效用函数

-a * （d（J）） / d（x）
J ：表示损失函数，x表示参数
导数（梯度）可以代表方向，对应J增大的方向

a称为学习率
a的取值影响获得最优解的速度
a的取值不合适，甚至得不到最优解
a是梯度下降法的一个超参数

并不是所有的函数都有唯一的极值点
解决方案：
    多次运行，随机化初始点
    梯度下降法的起始点也是一个超参数

线性回归法的函数具有唯一的极值点


gdSimulationRealize ： 梯度下降法模拟
useGdUnderLr : 在线性回归模型中使用梯度下降法
gdToQuantifyRealize : 在线性回归模型中使用梯度下降法（向量化实现）