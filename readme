K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。
该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。

kNN是一个不需要训练过程的算法

超参数：在算法运行前需要决定的参数，例如kNN的K值多项式回归(PolyRegression) : 线性回归的局限性是只能应用于存在线性关系的数据中，但是在实际生活中，很多数据之间是非线性关系，
            虽然也可以用线性回归拟合非线性回归，但是效果将会很差，这时候就需要对线性回归模型进行改进，使之能够拟合非线性数据。
模型参数：在算法学习过程中学习的参数

线性回归法(Linear Regression)
预测标准，MSE, RMSE, MAE, R Squared(官方推荐)

梯度下降法(Gradient Descent)

梯度上升法(PCA)

多项式回归(PolyRegression)

逻辑回归(LogisticRegression)

混淆矩阵(ConfusionMatrix)
    比如判断癌症的准确率为99.99%， 但是这个癌症发病率为0.01%，也就是说10000个人当中只要随便判断9999个人健康，准确度就达到99.99%
    看似算法模型准确度很高，其实是因为数据极度偏斜，因此只使用分类准确度远远不够
    
支撑向量机(SVM)

决策树(DecisionTree)

