pcaUse : 使用PCA求解主成分

向量方向是第一主成分
求出第一主成分后，如何求出下一个主成分？

数据进行改变，将数据在第一个主成分上的分量去掉
在新的数据上求第一主成分

getMainElements : 获取前n个主成分
pca : 实现pca的封装并将高维数据映射为低维数据
pcaSklTest : 使用scikit-learn中的PCA
denoisePca : 使用Pca对数据进行降噪

eigenFace ： 人脸识别和特征脸,数据集自己下载

矩阵乘法即把任意一个向量变成另一个方向或者长度都大多不同的新向量。
如果矩阵对某一向量或者某些向量只发生伸缩变换，不对向量产生旋转效果，则此向量就是特征向量，伸缩比例是特征值

具体的说，求特征向量，就是把矩阵A所代表的空间进行正交分解，使得A的向量集合可以表示为每个向量a在各个特征向量上的投影长度。
我们通常求特征值和特征向量即为求出这个矩阵能使哪些向量只发生拉伸，而方向不发生变化，观察其发生拉伸的程度。这样做的意义在于，
看清一个矩阵在哪些方面能产生最大的分散度（scatter），减少重叠，意味着更多的信息被保留下来。